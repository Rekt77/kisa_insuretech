{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "gender-age estimate.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1VfTAVhezNvk7m5_hQvdgNq0o1a7HNSm9",
      "authorship_tag": "ABX9TyP0i5OW+q6bJdM999Vky1hY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rekt77/kisa_insuretech/blob/master/gender_age_estimate.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S1De5-iZbzOT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2, glob, dlib\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# age_list: 기존에 모델을 개발한 사람이 만들어 놓은 것\n",
        "age_list = ['(0, 2)','(4, 6)','(8, 12)','(15, 20)','(25, 32)','(38, 43)','(48, 53)','(60, 100)']\n",
        "# gender_list: 기존에 모델을 개발한 사람이 만들어 놓은 것\n",
        "gender_list = ['Male', 'Female']\n",
        "\n",
        "# 얼굴을 detecting 하기위한 face detector\n",
        "detector = dlib.get_frontal_face_detector()\n",
        "\n",
        "# 기존에 학습되어있던 데이터로 진행\n",
        "# CNN기반 나이 판별 학습데이터\n",
        "age_net = cv2.dnn.readNetFromCaffe(\n",
        "          '/content/drive/My Drive/insuretech/gender/models/deploy_age.prototxt', \n",
        "          '/content/drive/My Drive/insuretech/gender/models/age_net.caffemodel')\n",
        "\n",
        "# CNN기반 성별 판별 학습데이터\n",
        "gender_net = cv2.dnn.readNetFromCaffe(\n",
        "          '/content/drive/My Drive/insuretech/gender/models/deploy_gender.prototxt', \n",
        "          '/content/drive/My Drive/insuretech/gender/models/gender_net.caffemodel')\n",
        "\n",
        "# 테스트 결과\n",
        "# 보정된 사진에는 이상한 결과가 나옴\n",
        "\n",
        "# glob을 통해서 이미지 파일을 전부 가져옴\n",
        "img_list = glob.glob('/content/drive/My Drive/insuretech/gender/img/*')\n",
        "\n",
        "# 이미지를 하나씩 읽음\n",
        "for img_path in img_list:\n",
        "  # image 읽기\n",
        "  img = cv2.imread(img_path)\n",
        "\n",
        "  # dlib의 detector객체 선언 후 이미지 대입\n",
        "  faces = detector(img)\n",
        "\n",
        "  # 찾은 얼굴 갯수만큼 이터레이팅\n",
        "  for face in faces:\n",
        "    # 얼굴의 상하좌우 좌표\n",
        "    x1, y1, x2, y2 = face.left(), face.top(), face.right(), face.bottom()\n",
        "\n",
        "    # 얼굴만 추출\n",
        "    # 행 데이터 -> y\n",
        "    # 열 데이터 -> x\n",
        "    face_img = img[y1:y2, x1:x2].copy()\n",
        "\n",
        "    # 계산을 하기 위해서\n",
        "    # 블롭이란 영상 등의 데이터를 포함할 수 있는 다차원 데이터 표현 방식\n",
        "    # OpenCV에서 블롭은 Mat 타입의 4차원 행렬로 표현됩니다.\n",
        "    # mean은 각 BGR 에서 빼야하는 값, 모든 데이터에서 추출한 각 채널의 평균 -> 노이즈 제거\n",
        "    blob = cv2.dnn.blobFromImage(face_img, scalefactor=1, size=(227, 227),\n",
        "      mean=(78.4263377603, 87.7689143744, 114.895847746),\n",
        "      swapRB=False, crop=False)\n",
        "\n",
        "    # predict gender\n",
        "    gender_net.setInput(blob)\n",
        "    gender_preds = gender_net.forward()\n",
        "    gender = gender_list[gender_preds[0].argmax()]\n",
        "\n",
        "    # predict age\n",
        "    age_net.setInput(blob)\n",
        "    age_preds = age_net.forward()\n",
        "    age = age_list[age_preds[0].argmax()]\n",
        "\n",
        "    # visualize\n",
        "    cv2.rectangle(img, (x1, y1), (x2, y2), (255,255,255), 2)\n",
        "    overlay_text = '%s %s' % (gender, age)\n",
        "    cv2.putText(img, overlay_text, org=(x1, y1), fontFace=cv2.FONT_HERSHEY_SIMPLEX,\n",
        "      fontScale=1, color=(0,0,0), thickness=10)\n",
        "    cv2.putText(img, overlay_text, org=(x1, y1),\n",
        "      fontFace=cv2.FONT_HERSHEY_SIMPLEX, fontScale=1, color=(255,255,255), thickness=2)\n",
        "\n",
        "  cv2_imshow(img)\n",
        "  cv2.imwrite('/content/drive/My Drive/insuretech/gender/result/%s' % img_path.split('/')[-1], img)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}