{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pytorch_resnet34.ipynb",
      "provenance": [],
      "toc_visible": true,
      "mount_file_id": "1nK69pUjnGySVj80cD2kdf_1ojClpvl0u",
      "authorship_tag": "ABX9TyPeTn4bdGhBStV8uGWYXOvw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rekt77/kisa_insuretech/blob/master/pytorch_resnet34.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W_RW062I7UoD",
        "colab_type": "text"
      },
      "source": [
        "# RESNET34를 이용한 자동차 사진 분류\n",
        "\n",
        "![why resnet](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fk.kakaocdn.net%2Fdn%2FdrYEZ4%2FbtqwpSXYd8U%2FLF8RkIhWpAmsgR67nfnZsk%2Fimg.png)\n",
        "\n",
        "- 이미지 분류 대회에서 2015년도에 resnet이 좋은 결과를 보임\n",
        "- 레이어가 깊어 질수록 좋은 효과를 보이는 경향이 있음"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EKzhEdVa7cjJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "18a5b0f3-6519-4635-9ef4-ba3006de1218"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import time\n",
        "import os\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "print(torch.cuda.get_device_name(device))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda:0\n",
            "Tesla P100-PCIE-16GB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W3L9P11c7jsc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 자동차 데이터 저장경로\n",
        "dataset_dir = \"/content/drive/My Drive/insuretech/car/origin_data/\"\n",
        "\n",
        "# 데이터 전처리\n",
        "# randomhorizontalFlip() : 이미지 좌우반전하여 학습\n",
        "# randomRotation() : 이미지 회전하여 학습\n",
        "# Normalize() : 이미지를 0과 0.5 사이 값으로 정규화 한후 (pixel - 0.5) / 0.5 진행 -> 결과 == -1과 1사이의 값\n",
        "train_tfms = transforms.Compose([transforms.Resize((400, 400)),\n",
        "                                 transforms.RandomHorizontalFlip(),\n",
        "                                 transforms.RandomRotation(15),\n",
        "                                 transforms.ToTensor(),\n",
        "                                 transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "test_tfms = transforms.Compose([transforms.Resize((400, 400)),\n",
        "                                transforms.ToTensor(),\n",
        "                                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "dataset = torchvision.datasets.ImageFolder(root=dataset_dir+\"train_data\", transform = train_tfms)\n",
        "trainloader = torch.utils.data.DataLoader(dataset, batch_size = 10, shuffle=True, num_workers = 2)\n",
        "\n",
        "dataset2 = torchvision.datasets.ImageFolder(root=dataset_dir+\"test_data\", transform = test_tfms)\n",
        "testloader = torch.utils.data.DataLoader(dataset2, batch_size = 10, shuffle=False, num_workers = 2)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yr4VtyuO8EHY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_model(model, criterion, optimizer, scheduler, n_epochs = 5):\n",
        "    \n",
        "    losses = []\n",
        "    accuracies = []\n",
        "    test_accuracies = []\n",
        "\n",
        "    # set the model to train mode\n",
        "    model.train()\n",
        "\n",
        "    # train\n",
        "    for epoch in range(n_epochs):\n",
        "\n",
        "      # duration 체크\n",
        "        since = time.time()\n",
        "        running_loss = 0.0\n",
        "        running_correct = 0.0\n",
        "        for i, data in enumerate(trainloader, 0):\n",
        "            # 배치사이즈 크기 만큼의 사진을 받아오고 데이터를 inputs, 라벨을 labels에 저장\n",
        "            inputs, labels = data\n",
        "\n",
        "            #cuda에 변수 할당\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            #기울기 초기화\n",
        "            optimizer.zero_grad()\n",
        "            \n",
        "            # hypothesis\n",
        "            outputs = model(inputs)\n",
        "\n",
        "            # 출력은 11개 분류 각각에 대한 값으로 나타납니다.\n",
        "            # 어떤 분류에 대해서 더 높은 값이 나타난다는 것은, 신경망이 그 이미지가 해당 분류에 더 가깝다고 생각한다는 것입니다\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "            # loss값 구하기\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            # loss 최소화\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            \n",
        "            # calculate the loss/acc later\n",
        "            running_loss += loss.item()\n",
        "            running_correct += (labels==predicted).sum().item()\n",
        "\n",
        "\n",
        "        # loss 값 구하기\n",
        "        epoch_duration = time.time()-since\n",
        "        epoch_loss = running_loss/len(trainloader)\n",
        "\n",
        "        # running_correct/trainloader = 전체 데이터 중에 몇개를 맞추었는지\n",
        "        # trainloader는 배치사이즈 10으로 구성되어 있어서 실제 데이터보다 10분의 1크기\n",
        "        epoch_acc = 100.0*(running_correct/(len(trainloader)*10))\n",
        "        print(\"Epoch %s, duration: %d s, loss: %.4f, acc: %.4f\" % (epoch+1, epoch_duration, epoch_loss, epoch_acc))\n",
        "        \n",
        "        #losses.append(epoch_loss)\n",
        "        #accuracies.append(epoch_acc)\n",
        "        \n",
        "        # switch the model to eval mode to evaluate on test data\n",
        "        model.eval()\n",
        "        test_acc = eval_model(model)\n",
        "        #test_accuracies.append(test_acc)\n",
        "        \n",
        "        # re-set the model to train mode after validating\n",
        "        model.train()\n",
        "        scheduler.step(test_acc)\n",
        "        since = time.time()\n",
        "    print('Finished Training')\n",
        "    return model#, losses, accuracies, test_accuracies"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ts4Rh4688N_u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def eval_model(model):\n",
        "    correct = 0.0\n",
        "    total = 0.0\n",
        "    with torch.no_grad():\n",
        "        for i, data in enumerate(testloader, 0):\n",
        "            images, labels = data\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            \n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            \n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    test_acc = 100.0 * correct / total\n",
        "    print('Accuracy of the network on the test images: %d %%' % (\n",
        "        test_acc))\n",
        "    return test_acc"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-0NLbso8SNw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# resnet을 불러옴\n",
        "model_ft = models.resnet34(pretrained=True)\n",
        "\n",
        "# resnet convolution layer를 통과한 데이터가 몇개의 피쳐를 가지고 있는지\n",
        "# 선형결합을 위해 필요한 부분\n",
        "num_ftrs = model_ft.fc.in_features\n",
        "\n",
        "# 11개의 클래스로 분류하기 위함\n",
        "model_ft.fc = nn.Linear(num_ftrs, 11)\n",
        "model_ft = model_ft.to(device)\n",
        "\n",
        "# cross entropy loss를 구함\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# 경사하강법으로 최적화\n",
        "optimizer = optim.SGD(model_ft.parameters(), lr=0.01, momentum=0.9)\n",
        "\n",
        "# learning rate를 높이거나 낮추는 스케줄러\n",
        "lrscheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', patience=3, threshold = 0.9)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jR5BlUNM8dw-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "f0c87924-34d0-4610-bda2-85f42f743a81"
      },
      "source": [
        "# 학습 루틴 시작\n",
        "model_ft = train_model(model_ft, criterion, optimizer, lrscheduler, n_epochs=10)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1, duration: 7 s, loss: 2.6155, acc: 23.4091\n",
            "Accuracy of the network on the test images: 10 %\n",
            "Epoch 2, duration: 7 s, loss: 2.2497, acc: 35.9091\n",
            "Accuracy of the network on the test images: 36 %\n",
            "Epoch 3, duration: 7 s, loss: 1.4845, acc: 55.0000\n",
            "Accuracy of the network on the test images: 39 %\n",
            "Epoch 4, duration: 7 s, loss: 1.4396, acc: 57.0455\n",
            "Accuracy of the network on the test images: 50 %\n",
            "Epoch 5, duration: 7 s, loss: 0.8645, acc: 70.9091\n",
            "Accuracy of the network on the test images: 54 %\n",
            "Epoch 6, duration: 7 s, loss: 0.7341, acc: 76.3636\n",
            "Accuracy of the network on the test images: 48 %\n",
            "Epoch 7, duration: 7 s, loss: 0.5073, acc: 82.2727\n",
            "Accuracy of the network on the test images: 82 %\n",
            "Epoch 8, duration: 7 s, loss: 0.2279, acc: 92.5000\n",
            "Accuracy of the network on the test images: 85 %\n",
            "Epoch 9, duration: 7 s, loss: 0.1513, acc: 95.6818\n",
            "Accuracy of the network on the test images: 86 %\n",
            "Epoch 10, duration: 7 s, loss: 0.1521, acc: 94.7727\n",
            "Accuracy of the network on the test images: 87 %\n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NN_xJApT9Ojy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# tie the class indices to their names\n",
        "\n",
        "def find_classes(dir):\n",
        "    classes = os.listdir(dir)\n",
        "    classes.sort()\n",
        "    class_to_idx = {classes[i]: i for i in range(len(classes))}\n",
        "    return classes, class_to_idx\n",
        "classes, c_to_idx = find_classes(dataset_dir+\"train_data\")"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h9TZ3afO6mgV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "62f8a992-9803-4fbd-b2dc-9b2a63b33c0f"
      },
      "source": [
        "c_to_idx"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Hyundai Accent Sedan 2012': 0,\n",
              " 'Hyundai Azera Sedan 2012': 1,\n",
              " 'Hyundai Elantra Sedan 2007': 2,\n",
              " 'Hyundai Elantra Touring Hatchback 2012': 3,\n",
              " 'Hyundai Genesis Sedan 2012': 4,\n",
              " 'Hyundai Santa Fe SUV 2012': 5,\n",
              " 'Hyundai Sonata Hybrid Sedan 2012': 6,\n",
              " 'Hyundai Sonata Sedan 2012': 7,\n",
              " 'Hyundai Tucson SUV 2012': 8,\n",
              " 'Hyundai Veloster Hatchback 2012': 9,\n",
              " 'Hyundai Veracruz SUV 2012': 10}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9dAXXWP79PRE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "04a2156d-6af3-4581-b0c2-bb3334d4bbc5"
      },
      "source": [
        "total = 0\n",
        "correct = 0\n",
        "\n",
        "model_ft.eval()\n",
        "for imgs,labels in testloader:\n",
        "  imgs = imgs.to(device)\n",
        "  labels = labels.to(device)\n",
        "  hypothesis = model_ft(imgs).to(device)\n",
        "  predicted = torch.argmax(hypothesis.data, 1)\n",
        "  print(predicted)\n",
        "  print(labels)\n",
        "  total += labels.size(0)\n",
        "  correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy:', 100 * correct / total)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0, 0, 0, 0, 3, 0, 9, 0, 0, 0], device='cuda:0')\n",
            "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
            "tensor([0, 0, 0, 0, 0, 0, 8, 0, 0, 0], device='cuda:0')\n",
            "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
            "tensor([ 0, 10,  0,  0,  1,  1,  1,  1,  1,  1], device='cuda:0')\n",
            "tensor([0, 0, 0, 0, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
            "tensor([1, 1, 1, 1, 1, 1, 7, 1, 1, 1], device='cuda:0')\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
            "tensor([1, 1, 2, 2, 2, 2, 2, 2, 2, 2], device='cuda:0')\n",
            "tensor([1, 1, 2, 2, 2, 2, 2, 2, 2, 2], device='cuda:0')\n",
            "tensor([0, 2, 2, 0, 2, 2, 2, 2, 2, 2], device='cuda:0')\n",
            "tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2], device='cuda:0')\n",
            "tensor([2, 2, 0, 2, 0, 2, 2, 2, 2, 2], device='cuda:0')\n",
            "tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2], device='cuda:0')\n",
            "tensor([3, 3, 3, 3, 3, 3, 3, 3, 3, 3], device='cuda:0')\n",
            "tensor([3, 3, 3, 3, 3, 3, 3, 3, 3, 3], device='cuda:0')\n",
            "tensor([3, 3, 3, 3, 3, 4, 3, 3, 3, 3], device='cuda:0')\n",
            "tensor([3, 3, 3, 3, 3, 3, 3, 3, 3, 3], device='cuda:0')\n",
            "tensor([3, 3, 3, 3, 3, 3, 3, 3, 4, 4], device='cuda:0')\n",
            "tensor([3, 3, 3, 3, 3, 3, 3, 3, 4, 4], device='cuda:0')\n",
            "tensor([4, 4, 4, 4, 4, 4, 4, 4, 4, 4], device='cuda:0')\n",
            "tensor([4, 4, 4, 4, 4, 4, 4, 4, 4, 4], device='cuda:0')\n",
            "tensor([4, 4, 4, 4, 4, 4, 4, 4, 4, 4], device='cuda:0')\n",
            "tensor([4, 4, 4, 4, 4, 4, 4, 4, 4, 4], device='cuda:0')\n",
            "tensor([4, 4, 4, 4, 4, 4, 4, 5, 5, 5], device='cuda:0')\n",
            "tensor([4, 4, 4, 4, 4, 4, 4, 5, 5, 5], device='cuda:0')\n",
            "tensor([10,  5,  5,  5,  5,  5,  5,  5,  5,  5], device='cuda:0')\n",
            "tensor([5, 5, 5, 5, 5, 5, 5, 5, 5, 5], device='cuda:0')\n",
            "tensor([0, 5, 5, 5, 5, 5, 9, 5, 5, 5], device='cuda:0')\n",
            "tensor([5, 5, 5, 5, 5, 5, 5, 5, 5, 5], device='cuda:0')\n",
            "tensor([5, 5, 5, 8, 5, 5, 5, 6, 6, 6], device='cuda:0')\n",
            "tensor([5, 5, 5, 5, 5, 5, 5, 6, 6, 6], device='cuda:0')\n",
            "tensor([6, 6, 6, 6, 7, 6, 6, 1, 6, 6], device='cuda:0')\n",
            "tensor([6, 6, 6, 6, 6, 6, 6, 6, 6, 6], device='cuda:0')\n",
            "tensor([6, 6, 6, 0, 6, 6, 6, 6, 6, 6], device='cuda:0')\n",
            "tensor([6, 6, 6, 6, 6, 6, 6, 6, 6, 6], device='cuda:0')\n",
            "tensor([1, 7, 7, 7, 7, 7, 7, 7, 7, 1], device='cuda:0')\n",
            "tensor([7, 7, 7, 7, 7, 7, 7, 7, 7, 7], device='cuda:0')\n",
            "tensor([0, 7, 7, 1, 1, 7, 1, 7, 1, 1], device='cuda:0')\n",
            "tensor([7, 7, 7, 7, 7, 7, 7, 7, 7, 7], device='cuda:0')\n",
            "tensor([7, 7, 7, 7, 7, 8, 9, 8, 8, 8], device='cuda:0')\n",
            "tensor([7, 7, 7, 7, 7, 8, 8, 8, 8, 8], device='cuda:0')\n",
            "tensor([ 8,  8,  8,  8, 10,  0,  8,  8,  8,  8], device='cuda:0')\n",
            "tensor([8, 8, 8, 8, 8, 8, 8, 8, 8, 8], device='cuda:0')\n",
            "tensor([ 8,  8, 10,  8,  8,  8, 10,  8,  8,  8], device='cuda:0')\n",
            "tensor([8, 8, 8, 8, 8, 8, 8, 8, 8, 8], device='cuda:0')\n",
            "tensor([7, 8, 8, 8, 9, 9, 9, 9, 9, 9], device='cuda:0')\n",
            "tensor([8, 8, 8, 8, 9, 9, 9, 9, 9, 9], device='cuda:0')\n",
            "tensor([9, 9, 3, 9, 9, 1, 9, 9, 9, 9], device='cuda:0')\n",
            "tensor([9, 9, 9, 9, 9, 9, 9, 9, 9, 9], device='cuda:0')\n",
            "tensor([ 9, 10,  9,  9,  0,  9,  9,  9,  0,  9], device='cuda:0')\n",
            "tensor([9, 9, 9, 9, 9, 9, 9, 9, 9, 9], device='cuda:0')\n",
            "tensor([ 9,  9,  1, 10, 10, 10, 10, 10, 10, 10], device='cuda:0')\n",
            "tensor([ 9,  9, 10, 10, 10, 10, 10, 10, 10, 10], device='cuda:0')\n",
            "tensor([10, 10,  0, 10, 10, 10, 10, 10, 10, 10], device='cuda:0')\n",
            "tensor([10, 10, 10, 10, 10, 10, 10, 10, 10, 10], device='cuda:0')\n",
            "tensor([10, 10,  8, 10, 10, 10, 10, 10, 10, 10], device='cuda:0')\n",
            "tensor([10, 10, 10, 10, 10, 10, 10, 10, 10, 10], device='cuda:0')\n",
            "Accuracy: 87.0\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}